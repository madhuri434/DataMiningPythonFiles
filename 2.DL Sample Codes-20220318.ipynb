{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af6f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL Sample code 1\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1083a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4e75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0fbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7056dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26984785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7578\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7669\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.7435\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7435\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7409\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.5218 - accuracy: 0.7695\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7617\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7578\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7865\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7839\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.4925 - accuracy: 0.7734\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.5168 - accuracy: 0.7435\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.5592 - accuracy: 0.7513\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7721\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7630\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7643\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7591\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7747\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7422\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7565\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7721\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7682\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7617\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7578\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7852\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7604\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7812\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7760\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7617\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7760\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7630\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7539\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.5078 - accuracy: 0.7552\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.4966 - accuracy: 0.7695\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 971us/step - loss: 0.4723 - accuracy: 0.7773\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.5040 - accuracy: 0.7604\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.4957 - accuracy: 0.7760\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 959us/step - loss: 0.4974 - accuracy: 0.7786\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7604\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7812\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7565\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 938us/step - loss: 0.4889 - accuracy: 0.7760\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.5465 - accuracy: 0.7292\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7773\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7734\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 979us/step - loss: 0.4964 - accuracy: 0.7695\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7760\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7695\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7552\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7786\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7604\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7826\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7591\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7708\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.5032 - accuracy: 0.7513\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 938us/step - loss: 0.4629 - accuracy: 0.7695\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.4931 - accuracy: 0.7591\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.4686 - accuracy: 0.7721\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.4947 - accuracy: 0.7526\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 959us/step - loss: 0.4684 - accuracy: 0.7760\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7721\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7565\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7839\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7734\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.5010 - accuracy: 0.7565\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.5150 - accuracy: 0.7617\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.4987 - accuracy: 0.7643\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7812\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.4731 - accuracy: 0.7826\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 972us/step - loss: 0.4902 - accuracy: 0.7552\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 946us/step - loss: 0.5110 - accuracy: 0.7630\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 963us/step - loss: 0.4739 - accuracy: 0.7786\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 952us/step - loss: 0.5175 - accuracy: 0.7786\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.5029 - accuracy: 0.7682\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 979us/step - loss: 0.4905 - accuracy: 0.7591\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.4999 - accuracy: 0.7708\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.4813 - accuracy: 0.7630\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.5125 - accuracy: 0.7682\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.5526 - accuracy: 0.7357\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.4965 - accuracy: 0.7721\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7773\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 946us/step - loss: 0.4816 - accuracy: 0.7760\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.4749 - accuracy: 0.7839\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.4552 - accuracy: 0.7852\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 943us/step - loss: 0.4857 - accuracy: 0.7786\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.5106 - accuracy: 0.7539\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.7474\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7331\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7591\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7656\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 905us/step - loss: 0.4815 - accuracy: 0.7760\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 935us/step - loss: 0.4692 - accuracy: 0.7852\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.4670 - accuracy: 0.7930\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7773\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7695\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7865\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7760\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7826\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7917\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 964us/step - loss: 0.4697 - accuracy: 0.7786\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 944us/step - loss: 0.4809 - accuracy: 0.7578\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 936us/step - loss: 0.4972 - accuracy: 0.7643\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7865\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7617\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7747\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.4674 - accuracy: 0.7878\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.4505 - accuracy: 0.7917\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.4837 - accuracy: 0.7734\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.4944 - accuracy: 0.7643\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7643\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7839\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7812\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7591\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 945us/step - loss: 0.4478 - accuracy: 0.7865\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 958us/step - loss: 0.5203 - accuracy: 0.7695\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.4948 - accuracy: 0.7630\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 961us/step - loss: 0.4761 - accuracy: 0.7747\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 979us/step - loss: 0.4535 - accuracy: 0.7969\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7826\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7721\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.4718 - accuracy: 0.7799\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.4557 - accuracy: 0.7826\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.4601 - accuracy: 0.7995\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7812\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7891\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7891\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7708\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7565\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.8086\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 978us/step - loss: 0.4633 - accuracy: 0.7760\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7812\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7943\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 960us/step - loss: 0.4847 - accuracy: 0.7708\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7839\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 992us/step - loss: 0.4958 - accuracy: 0.7630\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7630\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7565\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7969\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 989us/step - loss: 0.4590 - accuracy: 0.7812\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 948us/step - loss: 0.4915 - accuracy: 0.7630\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 979us/step - loss: 0.4526 - accuracy: 0.7943\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7943\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.4565 - accuracy: 0.7982\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7878\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7578\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7721\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7865\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7826\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7812\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f924fdbefd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c1aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 901us/step - loss: 0.4278 - accuracy: 0.8099\n",
      "Accuracy: 80.99\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9348ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a41060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DL – Sample Code 2\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265bb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b54c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.1133 - accuracy: 0.4362\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4620 - accuracy: 0.4714\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 1000us/step - loss: 1.3429 - accuracy: 0.4909\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.2122 - accuracy: 0.4909\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.1082 - accuracy: 0.5026\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0014 - accuracy: 0.4935\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9927 - accuracy: 0.5052\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9365 - accuracy: 0.5000\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 996us/step - loss: 0.8377 - accuracy: 0.5990\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7844 - accuracy: 0.6211\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7852 - accuracy: 0.6263\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8050 - accuracy: 0.6289\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7750 - accuracy: 0.6393\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7184 - accuracy: 0.6393\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.6562\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.6393\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.6562\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.6510\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6628\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.6628\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6654\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1000us/step - loss: 0.6585 - accuracy: 0.6562\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 987us/step - loss: 0.6593 - accuracy: 0.6615\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6706\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6732\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6745\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6654\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.6641\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.6654\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6797\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6576\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6641\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6758\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6706\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6784\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6914\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.6836\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.6706\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.6823\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6810\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6719\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6888\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6888\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6758\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6628\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6888\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6823\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6719\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6719\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6966\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.6823\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.6641\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6667\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6836\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6745\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6927\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5968 - accuracy: 0.6823\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6875\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6771\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6758\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 992us/step - loss: 0.6178 - accuracy: 0.6732\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6641\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6862\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6823\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6862\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6875\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6797\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.6836\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6914\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.6719\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6927\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6927\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.6732\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6979\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6810\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.6979\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.6849\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6758\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6914\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.6810\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.7057\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6732\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6862\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6901\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6927\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.7135\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6927\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.6927\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6979\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.7057\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.6979\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7096\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.7161\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6966\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.6966\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.6953\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.7148\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7031\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7174\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6109 - accuracy: 0.6875\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6875\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7148\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5905 - accuracy: 0.6953\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6862\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7253\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7266\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7174\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7161\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7344\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7448\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7318\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7305\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7500\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7214\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7174\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7461\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.7474\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7240\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.7422\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7266\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.5361 - accuracy: 0.7396\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.5663 - accuracy: 0.7422\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.5814 - accuracy: 0.7305\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.5408 - accuracy: 0.7396\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 992us/step - loss: 0.5280 - accuracy: 0.7409\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.7448\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7331\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7500\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7396\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7461\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.7435\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7474\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7370\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7539\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7214\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7331\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7370\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7461\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7500\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7565\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.7422\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7292\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7539\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7487\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7279\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7422\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7461\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.7422\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.7630\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92509b0f40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x,y, epochs=150, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "774f39e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 825us/step - loss: 0.5305 - accuracy: 0.7435\n",
      "Model accuracy: 74.35\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x, y)\n",
    "print(\"Model accuracy: %.2f\"% (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b082710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x)\n",
    "print([round(x[0]) for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bf624f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 12)                108       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 12)                156       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 277\n",
      "Trainable params: 277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e7547",
   "metadata": {},
   "source": [
    "# DL Sample code 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ac711b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp38-cp38-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: requests in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (2.25.1)\n",
      "Collecting torch==1.11.0\n",
      "  Downloading torch-1.11.0-cp38-none-macosx_10_9_x86_64.whl (129.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 129.9 MB 126 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/vinay/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (1.26.4)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.11.0 torchvision-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03a3f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2640d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8334e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    " # number of rows in the dataset\n",
    "def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af81c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(8, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25e661e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # forward propagate input\n",
    "def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d9eb776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79a3b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(100):\n",
    "        # enumerate mini batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90b35be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8c38585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b0bd0d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CSVDataset' object has no attribute 'get_splits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3cb9933ce4dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkedro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSVDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-81ccd2aeaa38>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# calculate split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# prepare data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CSVDataset' object has no attribute 'get_splits'"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "from kedro.extras.datasets.pandas import CSVDataSet\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a9670b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "model = MLP(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b13854e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-2fec6735665d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_model(train_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74f2e8c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-994fe9482a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dl' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e2114f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-50cbe073d030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make a single prediction (expect class=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.99539\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05889\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.85243\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.02306\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.83398\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.37708\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.03760\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.85243\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.17755\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.59755\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.44945\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.60536\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.38223\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.84356\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.38542\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.58212\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.32192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.56971\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.29674\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.36946\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.47357\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.56811\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.51171\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.41078\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.46168\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.21266\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.34090\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.42267\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.54487\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.18641\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.45300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted: %.3f (class=%d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-b43ed2fdc01c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(row, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# retrieve numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make a single prediction (expect class=1)\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = predict(row, model)\n",
    "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac36dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15a6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
