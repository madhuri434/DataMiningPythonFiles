{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./images/DLI_Header.png\"></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the assessment for this course. While we have gone over a variety of algorithms, we haven't done the most important part. We still need to serve a user a recommendation!\n",
    "\n",
    "Not a problem. We have all the pieces, time to put them together. For this assessment, we've constructed a skeleton for an end-to-end recommender system by copying over some code from Labs 1 and 2. By using what we've learned about the strengths and weaknesses of these algorithms, it will be up to you to apply them in the correct places.\n",
    "\n",
    "The code we have from the previous lab is:\n",
    "* [als.py](assessment/als.py) - Train and predict with an alternating least squares model\n",
    "* [dataset.py](assessment/dataset.py) - Prepare a dataset into a tf.data\n",
    "* [wide_and_deep.py](assessment/wide_and_deep.py) Construct a Wide & Deep TensorFlow model\n",
    "* [utils.py](assessment/utils.py) - Helper functions such as calculating RMSE\n",
    "\n",
    "As a reference, we can also unzip the packaged notebooks from the previous lab by uploading them (with the upward pointing arrow above the file menu) and running the cell block below. Please keep in mind that these previous lab notebooks won't run in this lab3 coding environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open lab1_work.zip, lab1_work.zip.zip or lab1_work.zip.ZIP.\n",
      "unzip:  cannot find or open lab2_work.zip, lab2_work.zip.zip or lab2_work.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip lab1_work.zip -d lab1/\n",
    "!unzip lab2_work.zip -d lab2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. Here's the total pipeline we'll be constructing.\n",
    "\n",
    "<img src=\"images/endtoend.png\" height=\"300\" width=\"500\"/>\n",
    "\n",
    "The goal is to create two python files, [trainer.py](assessment/trainer.py) and [client.py](assessment/client.py). [trainer.py](assessment/trainer.py) will train both the Candidate Generator Model and the Candidate Scoring Model. [client.py](assessment/client.py) will return recommendations for a specified user from Triton.\n",
    "\n",
    "## Scoring\n",
    "* [1. Model Training](#1.-Model-Training)\n",
    " * [1.1 Candidate Generator Model](#1.1-Candidate-Generator-Model) - `30 Points`\n",
    " * [1.2 Candidate Scoring Model](#1.2-Candidate-Scoring-Model) - `30 Points`\n",
    "* [2. Model Deployment](#2.-Model-Deployment)\n",
    " * [2.1 Triton](#2.1-Triton) - `20 Points`\n",
    " * [2.2 Client Application](#2.2-Client-Application) - `20 Points`\n",
    "\n",
    "## 1. Model Training\n",
    "\n",
    "In [trainer.py](assessment/trainer.py), we have four functions:\n",
    "* `get_als_model`: Initializes and trains an ALS Model\n",
    "* `get_wide_and_deep_model`: Initializes and trains a Wide & Deep Model\n",
    "* `get_candidate_generator`: Creates a Candidate Generator Model\n",
    "* `get_candidate_scoring_model`: Creates a Candidate Scoring Model\n",
    "\n",
    "Each of them have a number of `FIXME`s. \n",
    "\n",
    "### 1.1 Candidate Generator Model\n",
    "For `get_candidate_generator`, implement either a ALS (`get_als_model`) or Wide & Deep model (`get_wide_and_deep_model`). It will be trained on the ratings data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "      <th>overall</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180332</td>\n",
       "      <td>781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55433</td>\n",
       "      <td>781</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34202</td>\n",
       "      <td>781</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77087</td>\n",
       "      <td>781</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67012</td>\n",
       "      <td>781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_index  item_index  overall  valid\n",
       "0      180332         781      1.0  False\n",
       "1       55433         781      2.0  False\n",
       "2       34202         781      5.0  False\n",
       "3       77087         781      4.0  False\n",
       "4       67012         781      1.0  False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"data/task_3_ratings.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Candidate Generator is focused on speed, and is meant to quickly reduce our item catalogue down to a few hundred that our user might like.\n",
    "\n",
    "One way we can speed up predictions for our users is to cache the results of the Candidate Generator. If we do this, including contextual information such as time and location is not so straightforward. We would need to cache different results for different combinations of time and place for the variety of different ways users can interact with our system.\n",
    "\n",
    "Let's keep things simple for now, and instead just focus on `user_index`, `item_index`, and `overall`.\n",
    "\n",
    "Whether ALS or Wide and Deep is chosen, the Candidate Generator must be fast in both training and prediction:\n",
    "\n",
    "* The Candidate Generator should be trained in less than 15 seconds `10 points`.\n",
    "* The Candidate Generator should have a Root Mean Squared Error of less than 1.3 on the Validation Dataset `10 points`.\n",
    "* The Candidate Generator should make predictions for the Validation Dataset in 0.005 seconds `10 points`.\n",
    "\n",
    "**While either algorithm can hypothetically pass these requirements, one will be significantly easier to implement than the other.**\n",
    "\n",
    "### 1.2 Candidate Scoring Model\n",
    "\n",
    "The goal of the Candidate Scorer Model is to take the candidates from the Generator Model, and to rank them in order of the user's predicted preference. While the Generator Model is focused on speed, the Scoring Model is focused on accuracy. Additionally, the Scoring Model can more easily incorporate contextual information as it is ran when a user asks for a recommendation.\n",
    "\n",
    "When we trained our Wide and Deep Model in Lab 2, our `metadata` was already joined with user rankings. However, in production when we're making a prediction for one user, our predictions will be based on our separate metadata table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_index</th>\n",
       "      <th>brand_index</th>\n",
       "      <th>category_0_0</th>\n",
       "      <th>category_0_1</th>\n",
       "      <th>category_0_2</th>\n",
       "      <th>category_0_3</th>\n",
       "      <th>category_1_0</th>\n",
       "      <th>category_1_1</th>\n",
       "      <th>category_1_2</th>\n",
       "      <th>category_1_3</th>\n",
       "      <th>...</th>\n",
       "      <th>category_1_2_index</th>\n",
       "      <th>salesRank_Electronics</th>\n",
       "      <th>salesRank_Camera</th>\n",
       "      <th>salesRank_Computers</th>\n",
       "      <th>salesRank_CellPhones</th>\n",
       "      <th>salesRank_CellPhones_NA</th>\n",
       "      <th>salesRank_Electronics_NA</th>\n",
       "      <th>salesRank_Camera_NA</th>\n",
       "      <th>salesRank_Computers_NA</th>\n",
       "      <th>price_filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>GPS &amp; Navigation</td>\n",
       "      <td>Vehicle GPS</td>\n",
       "      <td>Trucking GPS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>147236.0</td>\n",
       "      <td>18665.5</td>\n",
       "      <td>14369.5</td>\n",
       "      <td>254050.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>299.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computers &amp; Accessories</td>\n",
       "      <td>Touch Screen Tablet Accessories</td>\n",
       "      <td>Chargers &amp; Adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>147236.0</td>\n",
       "      <td>18665.5</td>\n",
       "      <td>14369.5</td>\n",
       "      <td>254050.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>49.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>337</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>eBook Readers &amp; Accessories</td>\n",
       "      <td>Power Adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>147236.0</td>\n",
       "      <td>18665.5</td>\n",
       "      <td>14369.5</td>\n",
       "      <td>254050.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3146</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Accessories &amp; Supplies</td>\n",
       "      <td>Audio &amp; Video Accessories</td>\n",
       "      <td>TV Accessories &amp; Parts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>147236.0</td>\n",
       "      <td>18665.5</td>\n",
       "      <td>14369.5</td>\n",
       "      <td>254050.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computers &amp; Accessories</td>\n",
       "      <td>Tablets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>147236.0</td>\n",
       "      <td>18665.5</td>\n",
       "      <td>14369.5</td>\n",
       "      <td>254050.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>188.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_index  brand_index category_0_0                 category_0_1  \\\n",
       "0           0            0  Electronics             GPS & Navigation   \n",
       "1           1            0  Electronics      Computers & Accessories   \n",
       "2           2          337  Electronics  eBook Readers & Accessories   \n",
       "3           3         3146  Electronics       Accessories & Supplies   \n",
       "4           4            0  Electronics      Computers & Accessories   \n",
       "\n",
       "                      category_0_2            category_0_3 category_1_0  \\\n",
       "0                      Vehicle GPS            Trucking GPS          NaN   \n",
       "1  Touch Screen Tablet Accessories     Chargers & Adapters          NaN   \n",
       "2                   Power Adapters                     NaN          NaN   \n",
       "3        Audio & Video Accessories  TV Accessories & Parts          NaN   \n",
       "4                          Tablets                     NaN          NaN   \n",
       "\n",
       "  category_1_1 category_1_2 category_1_3  ...  category_1_2_index  \\\n",
       "0          NaN          NaN          NaN  ...                 101   \n",
       "1          NaN          NaN          NaN  ...                 101   \n",
       "2          NaN          NaN          NaN  ...                 101   \n",
       "3          NaN          NaN          NaN  ...                 101   \n",
       "4          NaN          NaN          NaN  ...                 101   \n",
       "\n",
       "   salesRank_Electronics  salesRank_Camera  salesRank_Computers  \\\n",
       "0               147236.0           18665.5              14369.5   \n",
       "1               147236.0           18665.5              14369.5   \n",
       "2               147236.0           18665.5              14369.5   \n",
       "3               147236.0           18665.5              14369.5   \n",
       "4               147236.0           18665.5              14369.5   \n",
       "\n",
       "   salesRank_CellPhones  salesRank_CellPhones_NA  salesRank_Electronics_NA  \\\n",
       "0              254050.0                    False                     False   \n",
       "1              254050.0                    False                     False   \n",
       "2              254050.0                    False                     False   \n",
       "3              254050.0                    False                     False   \n",
       "4              254050.0                    False                     False   \n",
       "\n",
       "   salesRank_Camera_NA  salesRank_Computers_NA  price_filled  \n",
       "0                False                   False        299.99  \n",
       "1                False                   False         49.95  \n",
       "2                False                   False         19.65  \n",
       "3                False                   False         29.99  \n",
       "4                False                   False        188.88  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"data/task_3_metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should update our training data to reflect this. We've kept our training data from Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (9,10,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>brand</th>\n",
       "      <th>category_0_0</th>\n",
       "      <th>category_0_1</th>\n",
       "      <th>category_0_2</th>\n",
       "      <th>category_0_3</th>\n",
       "      <th>category_1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "      <th>brand_index</th>\n",
       "      <th>als_prediction</th>\n",
       "      <th>user_embed_0</th>\n",
       "      <th>user_embed_1</th>\n",
       "      <th>item_embed_0</th>\n",
       "      <th>item_embed_1</th>\n",
       "      <th>category_0_2_index</th>\n",
       "      <th>category_1_2_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARA6X7G3KBX39</td>\n",
       "      <td>B00005B4BW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1042243200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera &amp; Photo</td>\n",
       "      <td>Lighting &amp; Studio</td>\n",
       "      <td>Photo Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>180332</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>3.105687</td>\n",
       "      <td>1.451223</td>\n",
       "      <td>-2.425463</td>\n",
       "      <td>0.715103</td>\n",
       "      <td>-1.195170</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A231WM2Z2JL0U3</td>\n",
       "      <td>B00005B4BW</td>\n",
       "      <td>2.0</td>\n",
       "      <td>965433600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera &amp; Photo</td>\n",
       "      <td>Lighting &amp; Studio</td>\n",
       "      <td>Photo Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55433</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>3.532970</td>\n",
       "      <td>1.650880</td>\n",
       "      <td>-2.759162</td>\n",
       "      <td>0.769520</td>\n",
       "      <td>-1.286120</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1O130H3XTF5WF</td>\n",
       "      <td>B00005B4BW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>954460800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera &amp; Photo</td>\n",
       "      <td>Lighting &amp; Studio</td>\n",
       "      <td>Photo Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34202</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>3.962095</td>\n",
       "      <td>1.851401</td>\n",
       "      <td>-3.094298</td>\n",
       "      <td>0.820172</td>\n",
       "      <td>-1.370778</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2IIZ25SZSQGCC</td>\n",
       "      <td>B00005B4BW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1030233600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera &amp; Photo</td>\n",
       "      <td>Lighting &amp; Studio</td>\n",
       "      <td>Photo Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>77087</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>2.661104</td>\n",
       "      <td>1.243477</td>\n",
       "      <td>-2.078256</td>\n",
       "      <td>0.770355</td>\n",
       "      <td>-1.287510</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2BBDPGILE8EN4</td>\n",
       "      <td>B00005B4BW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1009497600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Camera &amp; Photo</td>\n",
       "      <td>Lighting &amp; Studio</td>\n",
       "      <td>Photo Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>67012</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>3.232237</td>\n",
       "      <td>1.510355</td>\n",
       "      <td>-2.524297</td>\n",
       "      <td>0.709057</td>\n",
       "      <td>-1.185062</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  unixReviewTime brand category_0_0  \\\n",
       "0   ARA6X7G3KBX39  B00005B4BW      1.0      1042243200   NaN  Electronics   \n",
       "1  A231WM2Z2JL0U3  B00005B4BW      2.0       965433600   NaN  Electronics   \n",
       "2  A1O130H3XTF5WF  B00005B4BW      5.0       954460800   NaN  Electronics   \n",
       "3  A2IIZ25SZSQGCC  B00005B4BW      4.0      1030233600   NaN  Electronics   \n",
       "4  A2BBDPGILE8EN4  B00005B4BW      1.0      1009497600   NaN  Electronics   \n",
       "\n",
       "     category_0_1       category_0_2  category_0_3 category_1_0  ...  \\\n",
       "0  Camera & Photo  Lighting & Studio  Photo Studio          NaN  ...   \n",
       "1  Camera & Photo  Lighting & Studio  Photo Studio          NaN  ...   \n",
       "2  Camera & Photo  Lighting & Studio  Photo Studio          NaN  ...   \n",
       "3  Camera & Photo  Lighting & Studio  Photo Studio          NaN  ...   \n",
       "4  Camera & Photo  Lighting & Studio  Photo Studio          NaN  ...   \n",
       "\n",
       "  user_index item_index brand_index  als_prediction  user_embed_0  \\\n",
       "0     180332        781           0        3.105687      1.451223   \n",
       "1      55433        781           0        3.532970      1.650880   \n",
       "2      34202        781           0        3.962095      1.851401   \n",
       "3      77087        781           0        2.661104      1.243477   \n",
       "4      67012        781           0        3.232237      1.510355   \n",
       "\n",
       "   user_embed_1  item_embed_0  item_embed_1  category_0_2_index  \\\n",
       "0     -2.425463      0.715103     -1.195170                  83   \n",
       "1     -2.759162      0.769520     -1.286120                  83   \n",
       "2     -3.094298      0.820172     -1.370778                  83   \n",
       "3     -2.078256      0.770355     -1.287510                  83   \n",
       "4     -2.524297      0.709057     -1.185062                  83   \n",
       "\n",
       "   category_1_2_index  \n",
       "0                 101  \n",
       "1                 101  \n",
       "2                 101  \n",
       "3                 101  \n",
       "4                 101  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_2_data = pd.read_csv(\"data/task_2_wide_and_deep.csv\")\n",
    "lab_2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `get_candidate_scoring_model` in [trainer.py](assessment/trainer.py) in order to calculate the [Gaussian Rank](https://medium.com/rapids-ai/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy-7c947e3397da) of our `metadata`'s `salesRank_Electronics` column. Then, join this column into `lab_2_data`.\n",
    "\n",
    "Finally, choose one of either ALS (`get_als_model`) or Wide and Deep model (`get_wide_and_deep_model`) to implement as the Candidate Scoring Model.\n",
    "\n",
    "Whether ALS or Wide and Deep is chosen, the Candidate Scoring Model needs to meet the following requirements:\n",
    "\n",
    "* The Candidate Scoring Model should be trained in less than 600 seconds `10 points`.\n",
    "* The Candidate Scoring Model should have a Root Mean Squared Error of less than 1.175 on the Validation Dataset `10 points`.\n",
    "* The Candidate Scoring Model should make predictions for the Validation Dataset in 30 seconds `10 points`.\n",
    "\n",
    "**While either algorithm can hypothetically pass these requirements, one will be significantly easier to implement than the other.** Run the below cell to verify that [trainer.py](assessment/trainer.py) has been correctly implemented for both Candidate Generation and Candidate Scoring, meeting all of the above requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 185, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 155, in _get_module_details\n",
      "    code = loader.get_code(mod_name)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 916, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/dli/task/assessment/trainer.py\", line 32\n",
      "    }\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!python3 -m assessment.trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Deployment\n",
    "\n",
    "If the above code passed, it should have saved the components for the Candidate Generation Model and the Candidate Scoring Model. We'll need to load them into Triton and our client application. Let's start with Triton.\n",
    "\n",
    "### 2.1 Triton\n",
    "\n",
    "Open the File Browser (Ctrl/Command + Shift + F) to see the lab's file directory on the left (The list may need to be refreshed). The Candidate Scoring Model should now be saved to a folder on the left called `candidate_scorer`. Load it into `model_repository` using the following structure:\n",
    "\n",
    "`model_repository/\n",
    "  candidate_scorer/\n",
    "    config.pbtxt\n",
    "    1/\n",
    "      model.savedmodel/\n",
    "        <tensorflow_saved_model_files>/\n",
    "          ...\n",
    "`\n",
    "\n",
    "Feel free to use the [previous lab](3-03_triton.ipynb) as a guide. The below cell will **delete and rebuild** a `candidate_scorer` folder in `model_repository`. Please complete the `FIXME` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf model_repository/candidate_scorer ||:; mkdir model_repository/candidate_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FIXME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9113411e55a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'candidate_scorer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFIXME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtf_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_tensorflow_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFIXME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FIXME' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from nvtabular.inference.triton.ensemble import export_tensorflow_model\n",
    "\n",
    "model_name = 'candidate_scorer'\n",
    "model = tf.keras.models.load_model(FIXME)\n",
    "tf_config = export_tensorflow_model(model, model_name, FIXME, version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's verify that the model is running on Triton. `20 points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonhttpclient\n",
    "\n",
    "try:\n",
    "    triton_client = tritonhttpclient.InferenceServerClient(url=\"triton:8000\", verbose=True)\n",
    "    print(\"client created.\")\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))\n",
    "\n",
    "triton_client.get_model_repository_index()\n",
    "triton_client.load_model(model_name=model_name)\n",
    "triton_client.is_model_ready(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once verified, run the code below to free the GPU for the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Client Application\n",
    "\n",
    "We have our models, and our Candidate Scorer is loaded into Triton. Time for the magic to happen. Let's string everything together in [client.py](assessment/client.py) where there are a number of TODOs.\n",
    "\n",
    "First, load your Candidate Generation Model and use it to find a user's top 16 (`BATCH_SIZE`) recommendations.\n",
    "Second, specify the metadata columns specific to your Candidate Scoring Model.\n",
    "Finally, fix the `for` loop to format the data for Triton.\n",
    "\n",
    "For both the Candidate Generation Model and the Candidate Scoring Model, CuPy's/NumPy's [argpartition](https://numpy.org/doc/stable/reference/generated/numpy.argpartition.html) function are used to quickly separate top scoring items versus low scoring items.\n",
    "\n",
    "The following tests are in place:\n",
    "* Prediction for one user's top 16 items takes less than `2` seconds `10 points`\n",
    "* The average predicted score for user `131676`'s top 4 recommended items is greater than `4.2`. `10 points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m assessment.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got both `Tests pass!` for [1. Model Training](#1.-Model-Training) and [2. Model Deployment](#2.-Model-Deployment)? Run the cell below for the final check! This will verify your code against our assessment server, and if it passes, will qualify you for a certificate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_assessment import run_assessment\n",
    "run_assessment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Certificate\n",
    "If you passed the assessment, please return to the course page (shown below) and click the \"ASSESS TASK\" button, which will generate your certificate for the course.\n",
    "\n",
    "<img src=\"images/run_assess_task.png\" height=\"300\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./images/DLI_Header.png\"></a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
