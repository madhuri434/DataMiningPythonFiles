{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./images/DLI_Header.png\"></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker for Recommender Systems\n",
    "\n",
    "When it comes time to take a model from experiment to production, there are many operational aspects to consider. Running a model out of a notebook is difficult to scale to millions of users. Considering how many items we could be making predictions for and how active our user base might be, we could easily be making thousands of predictions per second! (For comparison, Netflix receives [20,000 requests per second during peak traffic](https://netflixtechblog.com/making-the-netflix-api-more-resilient-a8ec62159c2d))\n",
    "\n",
    "There are many different strategies to scale, but we'll be discussing [Docker](https://www.docker.com/).\n",
    "\n",
    "## Objectives\n",
    "* Understand how to set up a Docker container\n",
    "  * [1. Dockerfile](#1.-Dockerfile)\n",
    "* Understand how to set up multiple containers with [Docker Compose](https://docs.docker.com/compose/)\n",
    "  * [2. Docker Compose](#2.-Docker-Compose)\n",
    "\n",
    "## 1. Dockerfile\n",
    "\n",
    "Docker is a library for making [containers](https://www.docker.com/resources/what-container), which is a way to package code and its dependencies so it can easily be copied and transported to different computing environments. They are similar to [virtual machines](https://en.wikipedia.org/wiki/Virtual_machine). A virtual machine has its own virtualized hardware and operating system separate from its host machine, but a container uses its host machine's operating system.\n",
    "\n",
    "Let's get meta for a moment, and look at the [Dockerfile](https://docs.docker.com/engine/reference/builder/) for this class by running the cell below. There are a number of Docker commands that we used to build this notebook environment:\n",
    "* [FROM](https://docs.docker.com/engine/reference/builder/#from): The base container to initially build from. Containers can be built on top of other containers. In our case, we'll be using [NVIDIA's TensorFlow container](https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow) which already configures TensorFlow to run on top of a recent version of CUDA.\n",
    "* [ENV](https://docs.docker.com/engine/reference/builder/#env): Sets an environmental variable.\n",
    "* [RUN](https://docs.docker.com/engine/reference/builder/#run): Run a command line argument.\n",
    "* [WORKDIR](https://docs.docker.com/engine/reference/builder/#workdir): Change the working directory inside the container. `RUN cd` is ineffective as each `RUN` command gets a fresh shell as described in this [Stack Overflow](https://stackoverflow.com/questions/58847410/difference-between-run-cd-and-workdir-in-dockerfile) host.\n",
    "* [ADD](https://docs.docker.com/engine/reference/builder/#add): Copy data from the build environment into the docker container. In this case we're copying the labs, like this one here.\n",
    "* [EXPOSE](https://docs.docker.com/engine/reference/builder/#expose): Listen to the specified port. This lab is connecting to port `8888`.\n",
    "* [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint): Allows us to run our container as an executable and pass command line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">FROM</span> <span class=\"s\">nvcr.io/nvidia/merlin/merlin-tensorflow-training:0.5.3</span>\n",
       "\n",
       "<span class=\"c\"># nodejs is installed in the base image and is required to perform</span>\n",
       "<span class=\"c\"># `jupyter lab build` below. However, the PATH to node is not set</span>\n",
       "<span class=\"c\"># until the containers&#39;s shell is loaded and its .bashrc is sourced.</span>\n",
       "<span class=\"c\"># So, we need to set it here to use node in the Docker image build.</span>\n",
       "<span class=\"k\">ENV</span> <span class=\"nv\">PATH</span><span class=\"o\">=</span>/usr/local/nvm/versions/node/v14.4.0/bin:<span class=\"nv\">$PATH</span>\n",
       "\n",
       "<span class=\"c\"># Install apps and libraries not found in the base image.</span>\n",
       "<span class=\"k\">RUN</span> python3 -m pip install --upgrade <span class=\"nv\">jupyterlab</span><span class=\"o\">==</span><span class=\"m\">3</span>.1.0\n",
       "<span class=\"k\">RUN</span> python3 -m pip install matplotlib\n",
       "<span class=\"k\">RUN</span> apt-get update\n",
       "<span class=\"k\">RUN</span> apt-get -y install graphviz\n",
       "<span class=\"k\">RUN</span> apt-get -y install python3-pydot\n",
       "<span class=\"k\">RUN</span> apt-get -y install cmake\n",
       "<span class=\"k\">RUN</span> apt-get -y install tree\n",
       "\n",
       "<span class=\"c\"># Install Triton client libraries</span>\n",
       "<span class=\"k\">RUN</span> mkdir clients\n",
       "<span class=\"k\">WORKDIR</span><span class=\"s\"> /clients</span>\n",
       "<span class=\"k\">RUN</span> wget https://github.com/NVIDIA/triton-inference-server/releases/download/v2.0.0/v2.0.0_ubuntu1804.clients.tar.gz\n",
       "<span class=\"k\">RUN</span> tar xzf v2.0.0_ubuntu1804.clients.tar.gz\n",
       "<span class=\"k\">WORKDIR</span><span class=\"s\"> /clients/python</span>\n",
       "<span class=\"k\">RUN</span> pip install tritonclientutils-2.0.0-py3-none-any.whl\n",
       "<span class=\"k\">RUN</span> pip install tritongrpcclient-2.0.0-py3-none-any.whl\n",
       "<span class=\"k\">RUN</span> pip install tritonhttpclient-2.0.0-py3-none-any.whl\n",
       "<span class=\"k\">RUN</span> pip install tritonshmutils-2.0.0-py3-none-manylinux1_x86_64.whl\n",
       "<span class=\"k\">RUN</span> pip install jupyterlab\n",
       "\n",
       "<span class=\"c\"># Install NVTabular</span>\n",
       "<span class=\"k\">WORKDIR</span><span class=\"s\"> /nvtabular</span>\n",
       "<span class=\"k\">RUN</span> git pull origin v0.9.0\n",
       "<span class=\"k\">WORKDIR</span><span class=\"s\"> /</span>\n",
       "\n",
       "<span class=\"c\"># Make assessment running scripts available in notebooks</span>\n",
       "<span class=\"k\">ENV</span> <span class=\"nv\">PYTHONPATH</span><span class=\"o\">=</span>/dli/assessment/notebook_helpers\n",
       "\n",
       "<span class=\"c\"># Run the command to build the Jupyter lab</span>\n",
       "<span class=\"k\">RUN</span> curl -fsSL https://deb.nodesource.com/setup_16.x <span class=\"p\">|</span> bash -\n",
       "<span class=\"k\">RUN</span> apt-get install -y nodejs\n",
       "<span class=\"k\">RUN</span> python3 -m jupyter lab build\n",
       "\n",
       "<span class=\"c\"># Create working directory to add repo.</span>\n",
       "<span class=\"k\">WORKDIR</span><span class=\"s\"> /dli</span>\n",
       "\n",
       "<span class=\"c\"># Load contents into student working directory.</span>\n",
       "<span class=\"k\">ADD</span> . .\n",
       "\n",
       "<span class=\"c\"># Set the initial working directory for lab.</span>\n",
       "<span class=\"k\">WORKDIR</span><span class=\"s\"> /dli/task</span>\n",
       "\n",
       "<span class=\"c\"># Jupyter listens on 8888.</span>\n",
       "<span class=\"k\">EXPOSE</span><span class=\"s\"> 8888</span>\n",
       "<span class=\"k\">ENTRYPOINT</span> <span class=\"p\">[</span><span class=\"s2\">&quot;/dli/entrypoint.sh&quot;</span><span class=\"p\">]</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{FROM} \\PY{l+s}{nvcr.io/nvidia/merlin/merlin\\PYZhy{}tensorflow\\PYZhy{}training:0.5.3}\n",
       "\n",
       "\\PY{c}{\\PYZsh{} nodejs is installed in the base image and is required to perform}\n",
       "\\PY{c}{\\PYZsh{} `jupyter lab build` below. However, the PATH to node is not set}\n",
       "\\PY{c}{\\PYZsh{} until the containers\\PYZsq{}s shell is loaded and its .bashrc is sourced.}\n",
       "\\PY{c}{\\PYZsh{} So, we need to set it here to use node in the Docker image build.}\n",
       "\\PY{k}{ENV} \\PY{n+nv}{PATH}\\PY{o}{=}/usr/local/nvm/versions/node/v14.4.0/bin:\\PY{n+nv}{\\PYZdl{}PATH}\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Install apps and libraries not found in the base image.}\n",
       "\\PY{k}{RUN} python3 \\PYZhy{}m pip install \\PYZhy{}\\PYZhy{}upgrade \\PY{n+nv}{jupyterlab}\\PY{o}{=}\\PY{o}{=}\\PY{l+m}{3}.1.0\n",
       "\\PY{k}{RUN} python3 \\PYZhy{}m pip install matplotlib\n",
       "\\PY{k}{RUN} apt\\PYZhy{}get update\n",
       "\\PY{k}{RUN} apt\\PYZhy{}get \\PYZhy{}y install graphviz\n",
       "\\PY{k}{RUN} apt\\PYZhy{}get \\PYZhy{}y install python3\\PYZhy{}pydot\n",
       "\\PY{k}{RUN} apt\\PYZhy{}get \\PYZhy{}y install cmake\n",
       "\\PY{k}{RUN} apt\\PYZhy{}get \\PYZhy{}y install tree\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Install Triton client libraries}\n",
       "\\PY{k}{RUN} mkdir clients\n",
       "\\PY{k}{WORKDIR}\\PY{l+s}{ /clients}\n",
       "\\PY{k}{RUN} wget https://github.com/NVIDIA/triton\\PYZhy{}inference\\PYZhy{}server/releases/download/v2.0.0/v2.0.0\\PYZus{}ubuntu1804.clients.tar.gz\n",
       "\\PY{k}{RUN} tar xzf v2.0.0\\PYZus{}ubuntu1804.clients.tar.gz\n",
       "\\PY{k}{WORKDIR}\\PY{l+s}{ /clients/python}\n",
       "\\PY{k}{RUN} pip install tritonclientutils\\PYZhy{}2.0.0\\PYZhy{}py3\\PYZhy{}none\\PYZhy{}any.whl\n",
       "\\PY{k}{RUN} pip install tritongrpcclient\\PYZhy{}2.0.0\\PYZhy{}py3\\PYZhy{}none\\PYZhy{}any.whl\n",
       "\\PY{k}{RUN} pip install tritonhttpclient\\PYZhy{}2.0.0\\PYZhy{}py3\\PYZhy{}none\\PYZhy{}any.whl\n",
       "\\PY{k}{RUN} pip install tritonshmutils\\PYZhy{}2.0.0\\PYZhy{}py3\\PYZhy{}none\\PYZhy{}manylinux1\\PYZus{}x86\\PYZus{}64.whl\n",
       "\\PY{k}{RUN} pip install jupyterlab\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Install NVTabular}\n",
       "\\PY{k}{WORKDIR}\\PY{l+s}{ /nvtabular}\n",
       "\\PY{k}{RUN} git pull origin v0.9.0\n",
       "\\PY{k}{WORKDIR}\\PY{l+s}{ /}\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Make assessment running scripts available in notebooks}\n",
       "\\PY{k}{ENV} \\PY{n+nv}{PYTHONPATH}\\PY{o}{=}/dli/assessment/notebook\\PYZus{}helpers\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Run the command to build the Jupyter lab}\n",
       "\\PY{k}{RUN} curl \\PYZhy{}fsSL https://deb.nodesource.com/setup\\PYZus{}16.x \\PY{p}{|} bash \\PYZhy{}\n",
       "\\PY{k}{RUN} apt\\PYZhy{}get install \\PYZhy{}y nodejs\n",
       "\\PY{k}{RUN} python3 \\PYZhy{}m jupyter lab build\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Create working directory to add repo.}\n",
       "\\PY{k}{WORKDIR}\\PY{l+s}{ /dli}\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Load contents into student working directory.}\n",
       "\\PY{k}{ADD} . .\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Set the initial working directory for lab.}\n",
       "\\PY{k}{WORKDIR}\\PY{l+s}{ /dli/task}\n",
       "\n",
       "\\PY{c}{\\PYZsh{} Jupyter listens on 8888.}\n",
       "\\PY{k}{EXPOSE}\\PY{l+s}{ 8888}\n",
       "\\PY{k}{ENTRYPOINT} \\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}/dli/entrypoint.sh\\PYZdq{}}\\PY{p}{]}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "FROM nvcr.io/nvidia/merlin/merlin-tensorflow-training:0.5.3\n",
       "\n",
       "# nodejs is installed in the base image and is required to perform\n",
       "# `jupyter lab build` below. However, the PATH to node is not set\n",
       "# until the containers's shell is loaded and its .bashrc is sourced.\n",
       "# So, we need to set it here to use node in the Docker image build.\n",
       "ENV PATH=/usr/local/nvm/versions/node/v14.4.0/bin:$PATH\n",
       "\n",
       "# Install apps and libraries not found in the base image.\n",
       "RUN python3 -m pip install --upgrade jupyterlab==3.1.0\n",
       "RUN python3 -m pip install matplotlib\n",
       "RUN apt-get update\n",
       "RUN apt-get -y install graphviz\n",
       "RUN apt-get -y install python3-pydot\n",
       "RUN apt-get -y install cmake\n",
       "RUN apt-get -y install tree\n",
       "\n",
       "# Install Triton client libraries\n",
       "RUN mkdir clients\n",
       "WORKDIR /clients\n",
       "RUN wget https://github.com/NVIDIA/triton-inference-server/releases/download/v2.0.0/v2.0.0_ubuntu1804.clients.tar.gz\n",
       "RUN tar xzf v2.0.0_ubuntu1804.clients.tar.gz\n",
       "WORKDIR /clients/python\n",
       "RUN pip install tritonclientutils-2.0.0-py3-none-any.whl\n",
       "RUN pip install tritongrpcclient-2.0.0-py3-none-any.whl\n",
       "RUN pip install tritonhttpclient-2.0.0-py3-none-any.whl\n",
       "RUN pip install tritonshmutils-2.0.0-py3-none-manylinux1_x86_64.whl\n",
       "RUN pip install jupyterlab\n",
       "\n",
       "# Install NVTabular\n",
       "WORKDIR /nvtabular\n",
       "RUN git pull origin v0.9.0\n",
       "WORKDIR /\n",
       "\n",
       "# Make assessment running scripts available in notebooks\n",
       "ENV PYTHONPATH=/dli/assessment/notebook_helpers\n",
       "\n",
       "# Run the command to build the Jupyter lab\n",
       "RUN curl -fsSL https://deb.nodesource.com/setup_16.x | bash -\n",
       "RUN apt-get install -y nodejs\n",
       "RUN python3 -m jupyter lab build\n",
       "\n",
       "# Create working directory to add repo.\n",
       "WORKDIR /dli\n",
       "\n",
       "# Load contents into student working directory.\n",
       "ADD . .\n",
       "\n",
       "# Set the initial working directory for lab.\n",
       "WORKDIR /dli/task\n",
       "\n",
       "# Jupyter listens on 8888.\n",
       "EXPOSE 8888\n",
       "ENTRYPOINT [\"/dli/entrypoint.sh\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.Code(filename=\"../Dockerfile\", language=\"dockerfile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Dockerfile can be broken down into four goals:\n",
    "1. Install the necessary libraries to set up Jupyter.\n",
    "2. Install libraries for students to interact with in the notebooks.\n",
    "3. Install libraries to interact with a Triton server.\n",
    "4. Start the Jupyter server.\n",
    "\n",
    "Point 3 is how this all relates to recommender Systems. We're going to be working with a [Triton Server](https://docs.nvidia.com/deeplearning/triton-inference-server/master-user-guide/docs/) to scale out our Wide & Deep model from the previous lab so we can make web-based requests to it.\n",
    "\n",
    "## 2. Docker Compose\n",
    "\n",
    "For this lab, we're actually running multiple containers. Let's take a look at a different file to see how to set that up. Below is the [Docker Compose](https://docs.docker.com/compose/). It's similar to our `Dockerfile` above, but it's written with `.yml` instead.\n",
    "\n",
    "For instance, [image](https://docs.docker.com/compose/compose-file/#image) below corresponds with [FROM](https://docs.docker.com/engine/reference/builder/#from) above. Under the [services](https://docs.docker.com/compose/compose-file/#service-configuration-reference), we have a number of containers used to build the course.\n",
    "\n",
    "To focus on recommender systems, we're going to look at `triton` and `prometheus`. The other services are boilerplate for getting JupyterLab up and running, but they're visible for the curious.\n",
    "\n",
    "For now, let's focus on `triton` and break down each of the keys:\n",
    "* [command](https://docs.docker.com/compose/compose-file/#command): The command for the container to run once it's built. In this case, we're running the command to initiate the server if we had installed the Triton Inference Server Library locally as [described here](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/quickstart.html#run-triton-inference-server).\n",
    "* [image](https://docs.docker.com/compose/compose-file/#image): The base image that we're building off of, in this case, the [Triton Inference Server] image.\n",
    "* [shm-size](https://docs.docker.com/compose/compose-file/#shm_size): The amount of memory to share with the container. In this case, we're giving it 1 gigabyte for faster computation.\n",
    "* [ulimits](https://docs.docker.com/compose/compose-file/#ulimits): The max number of open file descriptors per process explained in this [Stack Overflow](https://stackoverflow.com/questions/24955883/what-is-the-max-opened-files-limitation-on-linux) post.\n",
    "* [ports](https://docs.docker.com/compose/compose-file/#ports): The ports to expose from the container.\n",
    "* [volumes](https://docs.docker.com/compose/compose-file/#volume-configuration-reference): A directory that can be shared between a container and it's host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># `version : &#39;2.3&#39;` lets us use the `runtime=nvidia` configuration so that our</span>\n",
       "<span class=\"c1\"># containers can interact with the GPU(s).</span>\n",
       "<span class=\"nt\">version</span><span class=\"p\">:</span> <span class=\"s\">&quot;2.3&quot;</span>\n",
       "\n",
       "<span class=\"c1\"># This will allow us to share a directory between our notebook and the Triton</span>\n",
       "<span class=\"c1\"># server.</span>\n",
       "<span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "  <span class=\"nt\">model_repository</span><span class=\"p\">:</span>\n",
       "  <span class=\"nt\">task_data</span><span class=\"p\">:</span>\n",
       "  <span class=\"nt\">assessment_results</span><span class=\"p\">:</span>\n",
       "\n",
       "<span class=\"nt\">services</span><span class=\"p\">:</span>\n",
       "  <span class=\"nt\">triton</span><span class=\"p\">:</span>\n",
       "    <span class=\"nt\">command</span><span class=\"p\">:</span> <span class=\"s\">&quot;tritonserver</span><span class=\"nv\"> </span><span class=\"s\">--model-repository=/models/</span><span class=\"nv\"> </span><span class=\"s\">--backend-config=tensorflow,version=2</span><span class=\"nv\"> </span><span class=\"s\">--model-control-mode=explicit&quot;</span>\n",
       "    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">nvcr.io/nvidia/merlin/merlin-inference:0.5.3</span>\n",
       "    <span class=\"nt\">runtime</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">nvidia</span>\n",
       "    <span class=\"nt\">shm_size</span><span class=\"p\">:</span> <span class=\"s\">&quot;1g&quot;</span>\n",
       "    <span class=\"nt\">ulimits</span><span class=\"p\">:</span>\n",
       "      <span class=\"nt\">memlock</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">-1</span>\n",
       "      <span class=\"nt\">stack</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">67108864</span>\n",
       "    <span class=\"nt\">ports</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">8000:8000</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">8001:8001</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">8002:8002</span>\n",
       "    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">model_repository:/models</span>\n",
       "\n",
       "  <span class=\"nt\">prometheus</span><span class=\"p\">:</span>\n",
       "    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">docker.io/prom/prometheus:latest</span>\n",
       "    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./prometheus.yml:/prometheus.yml</span>\n",
       "    <span class=\"nt\">command</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"s\">&quot;--config.file=/prometheus.yml&quot;</span>\n",
       "    <span class=\"nt\">ports</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">9090:9090</span>\n",
       "\n",
       "  <span class=\"c1\"># This is the Jupyter Lab :).</span>\n",
       "  <span class=\"nt\">lab</span><span class=\"p\">:</span>\n",
       "    <span class=\"nt\">runtime</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">nvidia</span>\n",
       "    <span class=\"nt\">environment</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">JUPYTER_TOKEN</span>\n",
       "\n",
       "    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "      <span class=\"c1\"># The s3_data_loader service below downloads data for the course through</span>\n",
       "      <span class=\"c1\"># these directories.</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">task_data:/dli/task/data</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./task/:/dli/task/</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./assessment/:/dli/assessment/</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">assessment_results:/dli/assessment_results/</span>\n",
       "      <span class=\"c1\"># This is the directory shared with our Triton server.</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">model_repository:/dli/task/model_repository</span>\n",
       "\n",
       "    <span class=\"nt\">ports</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">3000:3000</span>\n",
       "    <span class=\"nt\">links</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">triton</span>\n",
       "    <span class=\"nt\">depends_on</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">assessment</span>\n",
       "\n",
       "  <span class=\"c1\"># This is for the assessment. Good luck!</span>\n",
       "  <span class=\"nt\">assessment</span><span class=\"p\">:</span>\n",
       "    <span class=\"nt\">runtime</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">nvidia</span>\n",
       "    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">task_data:/dli/task/data</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./task/:/dli/task/</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./assessment/:/dli/assessment/</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">assessment_results:/dli/assessment_results/</span>\n",
       "      <span class=\"c1\"># This is the directory shared with our Triton server.</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">model_repository:/dli/task/model_repository</span>\n",
       "\n",
       "  <span class=\"c1\"># We use nginx to display the Jupyter GUI to students.</span>\n",
       "  <span class=\"nt\">nginx</span><span class=\"p\">:</span>\n",
       "    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">nginx:1.15.12-alpine</span>\n",
       "    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./nginx.conf:/etc/nginx/nginx.conf</span>\n",
       "    <span class=\"nt\">depends_on</span><span class=\"p\">:</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">lab</span>\n",
       "\n",
       "  <span class=\"c1\"># The data used for this course lives in aws and is loaded into the /data</span>\n",
       "  <span class=\"c1\"># directory.</span>\n",
       "  <span class=\"nt\">s3_data_loader</span><span class=\"p\">:</span>\n",
       "    <span class=\"nt\">image</span><span class=\"p\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">224292665285.dkr.ecr.us-east-1.amazonaws.com/s3_data_loader:latest</span>\n",
       "    <span class=\"nt\">volumes</span><span class=\"p\">:</span>\n",
       "      <span class=\"c1\"># Mount AWS credentials on the VM to give access to S3 buckets outside of</span>\n",
       "      <span class=\"c1\"># AWS. On AWS, permissions are granted via role and this file may not exist.</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">$HOME/.aws/credentials:/root/.aws/credentials:ro</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">./data_sources/data_sources:/var/data_sources</span>\n",
       "      <span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">task_data:/data</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} `version : \\PYZsq{}2.3\\PYZsq{}` lets us use the `runtime=nvidia` configuration so that our}\n",
       "\\PY{c+c1}{\\PYZsh{} containers can interact with the GPU(s).}\n",
       "\\PY{n+nt}{version}\\PY{p}{:} \\PY{l+s}{\\PYZdq{}}\\PY{l+s}{2.3}\\PY{l+s}{\\PYZdq{}}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} This will allow us to share a directory between our notebook and the Triton}\n",
       "\\PY{c+c1}{\\PYZsh{} server.}\n",
       "\\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "  \\PY{n+nt}{model\\PYZus{}repository}\\PY{p}{:}\n",
       "  \\PY{n+nt}{task\\PYZus{}data}\\PY{p}{:}\n",
       "  \\PY{n+nt}{assessment\\PYZus{}results}\\PY{p}{:}\n",
       "\n",
       "\\PY{n+nt}{services}\\PY{p}{:}\n",
       "  \\PY{n+nt}{triton}\\PY{p}{:}\n",
       "    \\PY{n+nt}{command}\\PY{p}{:} \\PY{l+s}{\\PYZdq{}}\\PY{l+s}{tritonserver}\\PY{n+nv}{ }\\PY{l+s}{\\PYZhy{}\\PYZhy{}model\\PYZhy{}repository=/models/}\\PY{n+nv}{ }\\PY{l+s}{\\PYZhy{}\\PYZhy{}backend\\PYZhy{}config=tensorflow,version=2}\\PY{n+nv}{ }\\PY{l+s}{\\PYZhy{}\\PYZhy{}model\\PYZhy{}control\\PYZhy{}mode=explicit}\\PY{l+s}{\\PYZdq{}}\n",
       "    \\PY{n+nt}{image}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{nvcr.io/nvidia/merlin/merlin\\PYZhy{}inference:0.5.3}\n",
       "    \\PY{n+nt}{runtime}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{nvidia}\n",
       "    \\PY{n+nt}{shm\\PYZus{}size}\\PY{p}{:} \\PY{l+s}{\\PYZdq{}}\\PY{l+s}{1g}\\PY{l+s}{\\PYZdq{}}\n",
       "    \\PY{n+nt}{ulimits}\\PY{p}{:}\n",
       "      \\PY{n+nt}{memlock}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{\\PYZhy{}1}\n",
       "      \\PY{n+nt}{stack}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{67108864}\n",
       "    \\PY{n+nt}{ports}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{8000:8000}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{8001:8001}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{8002:8002}\n",
       "    \\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{model\\PYZus{}repository:/models}\n",
       "\n",
       "  \\PY{n+nt}{prometheus}\\PY{p}{:}\n",
       "    \\PY{n+nt}{image}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{docker.io/prom/prometheus:latest}\n",
       "    \\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./prometheus.yml:/prometheus.yml}\n",
       "    \\PY{n+nt}{command}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+s}{\\PYZdq{}}\\PY{l+s}{\\PYZhy{}\\PYZhy{}config.file=/prometheus.yml}\\PY{l+s}{\\PYZdq{}}\n",
       "    \\PY{n+nt}{ports}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{9090:9090}\n",
       "\n",
       "  \\PY{c+c1}{\\PYZsh{} This is the Jupyter Lab :).}\n",
       "  \\PY{n+nt}{lab}\\PY{p}{:}\n",
       "    \\PY{n+nt}{runtime}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{nvidia}\n",
       "    \\PY{n+nt}{environment}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{JUPYTER\\PYZus{}TOKEN}\n",
       "\n",
       "    \\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "      \\PY{c+c1}{\\PYZsh{} The s3\\PYZus{}data\\PYZus{}loader service below downloads data for the course through}\n",
       "      \\PY{c+c1}{\\PYZsh{} these directories.}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{task\\PYZus{}data:/dli/task/data}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./task/:/dli/task/}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./assessment/:/dli/assessment/}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{assessment\\PYZus{}results:/dli/assessment\\PYZus{}results/}\n",
       "      \\PY{c+c1}{\\PYZsh{} This is the directory shared with our Triton server.}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{model\\PYZus{}repository:/dli/task/model\\PYZus{}repository}\n",
       "\n",
       "    \\PY{n+nt}{ports}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{3000:3000}\n",
       "    \\PY{n+nt}{links}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{triton}\n",
       "    \\PY{n+nt}{depends\\PYZus{}on}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{assessment}\n",
       "\n",
       "  \\PY{c+c1}{\\PYZsh{} This is for the assessment. Good luck!}\n",
       "  \\PY{n+nt}{assessment}\\PY{p}{:}\n",
       "    \\PY{n+nt}{runtime}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{nvidia}\n",
       "    \\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{task\\PYZus{}data:/dli/task/data}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./task/:/dli/task/}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./assessment/:/dli/assessment/}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{assessment\\PYZus{}results:/dli/assessment\\PYZus{}results/}\n",
       "      \\PY{c+c1}{\\PYZsh{} This is the directory shared with our Triton server.}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{model\\PYZus{}repository:/dli/task/model\\PYZus{}repository}\n",
       "\n",
       "  \\PY{c+c1}{\\PYZsh{} We use nginx to display the Jupyter GUI to students.}\n",
       "  \\PY{n+nt}{nginx}\\PY{p}{:}\n",
       "    \\PY{n+nt}{image}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{nginx:1.15.12\\PYZhy{}alpine}\n",
       "    \\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./nginx.conf:/etc/nginx/nginx.conf}\n",
       "    \\PY{n+nt}{depends\\PYZus{}on}\\PY{p}{:}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{lab}\n",
       "\n",
       "  \\PY{c+c1}{\\PYZsh{} The data used for this course lives in aws and is loaded into the /data}\n",
       "  \\PY{c+c1}{\\PYZsh{} directory.}\n",
       "  \\PY{n+nt}{s3\\PYZus{}data\\PYZus{}loader}\\PY{p}{:}\n",
       "    \\PY{n+nt}{image}\\PY{p}{:} \\PY{l+lScalar+lScalarPlain}{224292665285.dkr.ecr.us\\PYZhy{}east\\PYZhy{}1.amazonaws.com/s3\\PYZus{}data\\PYZus{}loader:latest}\n",
       "    \\PY{n+nt}{volumes}\\PY{p}{:}\n",
       "      \\PY{c+c1}{\\PYZsh{} Mount AWS credentials on the VM to give access to S3 buckets outside of}\n",
       "      \\PY{c+c1}{\\PYZsh{} AWS. On AWS, permissions are granted via role and this file may not exist.}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{\\PYZdl{}HOME/.aws/credentials:/root/.aws/credentials:ro}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{./data\\PYZus{}sources/data\\PYZus{}sources:/var/data\\PYZus{}sources}\n",
       "      \\PY{p+pIndicator}{\\PYZhy{}} \\PY{l+lScalar+lScalarPlain}{task\\PYZus{}data:/data}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "# `version : '2.3'` lets us use the `runtime=nvidia` configuration so that our\n",
       "# containers can interact with the GPU(s).\n",
       "version: \"2.3\"\n",
       "\n",
       "# This will allow us to share a directory between our notebook and the Triton\n",
       "# server.\n",
       "volumes:\n",
       "  model_repository:\n",
       "  task_data:\n",
       "  assessment_results:\n",
       "\n",
       "services:\n",
       "  triton:\n",
       "    command: \"tritonserver --model-repository=/models/ --backend-config=tensorflow,version=2 --model-control-mode=explicit\"\n",
       "    image: nvcr.io/nvidia/merlin/merlin-inference:0.5.3\n",
       "    runtime: nvidia\n",
       "    shm_size: \"1g\"\n",
       "    ulimits:\n",
       "      memlock: -1\n",
       "      stack: 67108864\n",
       "    ports:\n",
       "      - 8000:8000\n",
       "      - 8001:8001\n",
       "      - 8002:8002\n",
       "    volumes:\n",
       "      - model_repository:/models\n",
       "\n",
       "  prometheus:\n",
       "    image: docker.io/prom/prometheus:latest\n",
       "    volumes:\n",
       "      - ./prometheus.yml:/prometheus.yml\n",
       "    command:\n",
       "      - \"--config.file=/prometheus.yml\"\n",
       "    ports:\n",
       "      - 9090:9090\n",
       "\n",
       "  # This is the Jupyter Lab :).\n",
       "  lab:\n",
       "    runtime: nvidia\n",
       "    environment:\n",
       "      - JUPYTER_TOKEN\n",
       "\n",
       "    volumes:\n",
       "      # The s3_data_loader service below downloads data for the course through\n",
       "      # these directories.\n",
       "      - task_data:/dli/task/data\n",
       "      - ./task/:/dli/task/\n",
       "      - ./assessment/:/dli/assessment/\n",
       "      - assessment_results:/dli/assessment_results/\n",
       "      # This is the directory shared with our Triton server.\n",
       "      - model_repository:/dli/task/model_repository\n",
       "\n",
       "    ports:\n",
       "      - 3000:3000\n",
       "    links:\n",
       "      - triton\n",
       "    depends_on:\n",
       "      - assessment\n",
       "\n",
       "  # This is for the assessment. Good luck!\n",
       "  assessment:\n",
       "    runtime: nvidia\n",
       "    volumes:\n",
       "      - task_data:/dli/task/data\n",
       "      - ./task/:/dli/task/\n",
       "      - ./assessment/:/dli/assessment/\n",
       "      - assessment_results:/dli/assessment_results/\n",
       "      # This is the directory shared with our Triton server.\n",
       "      - model_repository:/dli/task/model_repository\n",
       "\n",
       "  # We use nginx to display the Jupyter GUI to students.\n",
       "  nginx:\n",
       "    image: nginx:1.15.12-alpine\n",
       "    volumes:\n",
       "      - ./nginx.conf:/etc/nginx/nginx.conf\n",
       "    depends_on:\n",
       "      - lab\n",
       "\n",
       "  # The data used for this course lives in aws and is loaded into the /data\n",
       "  # directory.\n",
       "  s3_data_loader:\n",
       "    image: 224292665285.dkr.ecr.us-east-1.amazonaws.com/s3_data_loader:latest\n",
       "    volumes:\n",
       "      # Mount AWS credentials on the VM to give access to S3 buckets outside of\n",
       "      # AWS. On AWS, permissions are granted via role and this file may not exist.\n",
       "      - $HOME/.aws/credentials:/root/.aws/credentials:ro\n",
       "      - ./data_sources/data_sources:/var/data_sources\n",
       "      - task_data:/data"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Code(filename=\"../docker-compose.yml\", language=\"yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "Docker is useful for production practices because it can be developed locally on one machine before deploying the configuration to a cloud service or server farm.\n",
    "\n",
    "We've already launched a Triton docker container when we launched the container with this lab. Check out the [next notebook](3-03_triton.ipynb) to start interacting with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"./images/DLI_Header.png\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
